
import json, math, csv, re
from pathlib import Path
from typing import Optional, Tuple, Dict
from datetime import datetime

RQ5_ROOT   = Path("../../Evaluation/Experiments/RQ5")
RES_PARENT = RQ5_ROOT / "Scripts"
OUT_PARENT = RQ5_ROOT / "results"
RES_DIR: Optional[Path] = None 

PREFIX = "cs_infer_results_"
PRED_KEYS = ("predict_score", "pred_score", "predicted_score", "prediction")

def latest_results_dir(parent: Path) -> Optional[Path]:
    cands = [p for p in parent.iterdir() if p.is_dir() and p.name.startswith(PREFIX)]
    if not cands:
        return None
    cands.sort(key=lambda p: p.name[len(PREFIX):])
    return cands[-1]

def safe_float(x):
    try:
        return float(x)
    except:
        return None

def ckpt_key(stem: str) -> str:

    return re.sub(r"__\d+$", "", stem)

def file_abs_errors(p: Path) -> Tuple[float,int]:
    """
    Return (sum_abs_err, n) over all rows with a usable prediction.
    """
    s1_all = 0.0
    n_all  = 0
    with p.open("r", encoding="utf-8") as f:
        for line in f:
            try:
                obj = json.loads(line)
            except:
                continue
            y = safe_float(obj.get("score"))
            if y is None:
                continue
            pred = None
            for k in PRED_KEYS:
                if k in obj:
                    pred = safe_float(obj.get(k))
                    if pred is not None:
                        break
            if pred is None:
                continue
            s1_all += abs(y - pred)
            n_all  += 1
    return s1_all, n_all

def to_mae(s1: float, n: int) -> float:
    return (s1 / n) if n > 0 else math.nan

def fmt(x: float) -> str:
    return f"{x:.6f}" if isinstance(x, float) and not math.isnan(x) else "NaN"

def classify_bucket(parts_lower) -> str:
   
    for part in parts_lower:
      
        if part == "local" or "local" in part:
            return "local"

   
    for part in parts_lower:
        if "baseline" in part or "baeline" in part or "baelime" in part or "basline" in part:
            # full
            if ("full" in part) or ("all" in part):
                return "baseline_full"
            # sampled
            if ("sample" in part) or ("subset" in part):
                return "baseline_sampled"

   
    if len(parts_lower) >= 2:
        label = parts_lower[1]
        if "local" in label:
            return "local"
        if "baseline" in label or "baeline" in label or "baelime" in label or "basline" in label:
            if "full" in label or "all" in label:
                return "baseline_full"
            if "sample" in label or "subset" in label:
                return "baseline_sampled"
    return ""

def main():
    root = RES_DIR or latest_results_dir(RES_PARENT)
    if root is None:
        print(f"[error] No '{PREFIX}*' under {RES_PARENT}")
        return

    run_tag = root.name[len(PREFIX):] if root.name.startswith(PREFIX) else datetime.now().strftime("%Y%m%d_%H%M%S")
    OUT_PARENT.mkdir(parents=True, exist_ok=True)
    out_csv = OUT_PARENT / f"mae_three_buckets_{run_tag}.csv"

    files = sorted(root.rglob("*.jsonl"))
    agg: Dict[Tuple[str,str], Dict[str,float]] = {}

    for p in files:
        rel = p.relative_to(root)
        parts = [s for s in rel.parts]              
        parts_l = [s.lower() for s in rel.parts]     
        exp = parts[0] if parts else "-"
        ck  = ckpt_key(p.stem)

        bucket = classify_bucket(parts_l)
        if not bucket:
            continue  

        d = agg.setdefault((exp, ck), {
            "local_s1":0.0,           "local_n":0,
            "basefull_s1":0.0,        "basefull_n":0,
            "basesampled_s1":0.0,     "basesampled_n":0,
        })

        s1_all, n_all = file_abs_errors(p)

        if bucket == "local":
            d["local_s1"] += s1_all;          d["local_n"] += n_all
        elif bucket == "baseline_full":
            d["basefull_s1"] += s1_all;       d["basefull_n"] += n_all
        elif bucket == "baseline_sampled":
            d["basesampled_s1"] += s1_all;    d["basesampled_n"] += n_all

   
    with out_csv.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow([
            "exp","ckpt",
            "mae_local",
            "mae_baseline_full",
            "mae_baseline_sampled",
        ])

        for (exp, ck), d in sorted(agg.items()):
            mae_local      = to_mae(d["local_s1"],       d["local_n"])
            mae_b_full     = to_mae(d["basefull_s1"],    d["basefull_n"])
            mae_b_sampled  = to_mae(d["basesampled_s1"], d["basesampled_n"])

            w.writerow([
                exp, ck,
                fmt(mae_local),
                fmt(mae_b_full),
                fmt(mae_b_sampled),
            ])

    print(f"outputs stored in {out_csv.resolve()}")

if __name__ == "__main__":
    main()
